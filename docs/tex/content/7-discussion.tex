\section{Discussion}

Our classifier performance is comparable to that of Fucci et al. (TODO: compare), which is positive considering the limited data collected.

When I started the thesis, we set a goal of answering two research questions:

\begin{itemize}
        \item RQ1. Can we train an EEG classifier to separate software developersâ€™ device activities?
        \item RQ2. Can we improve upon previous results in classifying code vs prose comprehension with EEG~?
\end{itemize}


\todo[inline]{Discussion of results}

\subsection{Applications to software engineering}

As we mentioned in the introduction, gaining insight into the brains of developers at work can be used to aid and enhance the productivity of developers in several ways.

Some to assist in development, like helping to identify developer confusion, but other applications could be imagined where a summary of the developers' brain activity during a particular commit (such as if the developer was confused, focused, tired).

\todo[inline]{Include image of mood attached in commit message from Fucci talk?}

\subsection{Applications to the average device user}

\todo[inline]{Merge with applications to software engineering?}

Applications of our results include:

\begin{itemize}
    \item Use the confidence in the task prediction as an alternative measurement of focus (not merely measuring that the subject was focused, but what they were focused on). 
    \item Detecting distraction.
\end{itemize}

\subsection{Threats to validity}

    During our work we've considered several potential threats to validity. Some of these arise from our limited and biased dataset, while others are about the task and methodology.

    Starting with our dataset, we collected on mostly right-handed males in their late 20s. This uniform/homogenous sample may lead to less data needed to train a classifier for that particular group, but doesn't necessarily generalize well to the population at large.

    Among our considerations, one threat to the validity is the stimuli images themselves (as seen in Figure~\ref{fig:tasks}). In Floyd et al.~the images used for prose comprehension are in fact more like a code review task, while Fucci et al.~modified the images to test comprehension, instead of ability to judge correctness. We also discovered that subjects found the prose stimuli used by Floyd et al.~confusing, and it would have been preferrable to use prose stimuli more like that used by Fucci et al.

    The stimuli images differ on more than just content. Examples of such differences are the background color, the difference in eye saccades while reading (eyes jump around more during the code tasks, where the user may have to jump between the code and the question about it). We haven't been able to discard the possibility that the front-heavy electrode placements (with reference electrode at Fpz) lead to much of the signal being from eye saccades. 

    Future research could evaluate this further either by using an eye tracker or by using an EEG device with different placements of both the electrodes and reference electrode.

    \todo[inline]{Investigate threats to validity mentioned by previous authors}

\subsection{Ethical considerations}

    When studying EEG data a range of ethical considerations arise. 

    \begin{itemize}
        \item Could the data be considered personally identifiable information (PII)? 
        \item How privacy sensitive are EEG recordings? Could they contain something the subject would rather keep private? (could have medical implications)
        \item How do we build large public datasets, while preserving participants privacy?
    \end{itemize}

    Companies such as Neurosity have taken an approach with their products where all the processing happens on-device, and only aggregates and classifier outputs are sent to the cloud for storage and presentation to the user.

    \add[inline]{Discuss ethics/privacy considerations of data collection, how it's dealt with in ActivityWatch, and implications of results on similar concerns apply to EEG data}

    \add[inline]{Mention OpenMined, https://github.com/OpenMined/PySyft, and similar tech (esp in the context of crowdsourcing data)}

\subsection{Democratization of neuroscience}

    This thesis was made possible due to the efforts of individuals and communities such as NeuroTechX to democratize neuroscience. Indeed, it is the explicit goal of the NeuroTechX eeg-notebooks project to `democratize the neuroscience experiment'. Combined with the rapid cost reduction of research-grade EEG equipment over the last decade it has enabled any programmer to design and perform high-quality neuroscience experiments.

    As development of BCIs advance and the consumer market for EEG devices grow (as evidenced by new devices being released with a regular cadence by InteraXon and Neurosity) we expect to see more uses and applications of these devices.

    Much of this work was made possible due to the efforts of communities such as NeuroTechX to democratize neuroscience by publishing tools and code for running experiments.

\subsection{Crowdsourcing data}

    Collecting data is a significant time sink for researchers, and efforts to crowdsource data from the general public are difficult for EEG as it still requires access to the equipment, the knowledge to operate it, as well as considerations like signal quality, electrode placement, and other factors that might invalidate the data.

    As part of the thesis work I've contributed to an effort in crowdsourcing EEG data collected from the experiments built in eeg-notebooks using consumer EEG devices like the Muse and OpenBCI\@. The effort, called the \href{https://neurotech-challenge.com/}{NeuroTech Challenge Series} (NTCS), is lead by John Griffiths at the University of Toronto.

    \add[inline]{Write about crowdsourcing of EEG data, including the potential of transfer learning and privacy considerations.}

