\chapter{Method}

Our method starts with gathering the data, and to get started with data collection we configure the equipment and tools needed to perform the experiment.

Once our data collection is done, we continue with our analysis by training a classifier using various machine learning methods.

\includegraphics[width=10cm]{img/method.png}

\section{Collection}

In order to perform our experiment and analysis, we need two types of data: EEG data, and device activity data to label the EEG data.

    \subsection{Collection of EEG data}

        EEG data was collected during organic device use and under controlled conditions.

        For both conditions, code from the open source eeg-notebooks~\cite{barachant_eeg-notebooks_2020} was adapted to record the raw EEG stream into a CSV file.

        Depending on the device used we require certain software to connect to the devices. We used muse-lsl for the Muse S~\cite{muse-lsl} which in turn uses Lab Streaming Layer. To support OpenBCI and Neurosity devices we used brainflow~\cite{noauthor_brainflow_2020}.

        \subsubsection{During organic device use}

            For the organic device use conditions, we primarily used the Muse S due the superior comfort and ease of use compared with the alternatives, making it especially suitable for long recordings.\footnote{A wet electrode cap system was also considered, but ultimately not investigated due to being inconvenient to setup.}

            The subject was then simply asked to go about their usual device activities, often consisting of a mix of work (email, writing prose, writing code) and leisure (watching YouTube, reading Twitter).

        \subsubsection{During code vs prose comprehension task}

            For the controlled condition, we ended up using the Muse S as well due to the comfort and ease of setup.

            \todo[inline]{Update with latest}
            We had 9 subjects, sampled by convenience. They were mostly male in their late 20s.

            We implemented the task in eeg-notebooks~\cite{barachant_eeg-notebooks_2020}, which uses previously mentioned libraries for data collection as well as PsychoPy~\cite{peirce_psychopy2_2019} to provide the stimuli.

            The experiment consists of presenting images with code or prose comprehension tasks, as seen in Figure~\ref{fig:codetask} and~\ref{fig:prosetask}.

            \begin{figure}[h]
                \begin{center}
                    \includegraphics[trim=0 120 0 0,clip,width=100mm]{img/final-1-1.png}
                \end{center}
                \caption{Sample of the code comprehension task}\label{fig:codetask}
            \end{figure}

            \begin{figure}[h]
                \begin{center}
                    \includegraphics[width=100mm]{img/bugs_1.PNG}
                \end{center}
                \caption{Sample of the prose review task}\label{fig:prosetask}
            \end{figure}

            Before each run, the subject was asked about their gender, age, and software development experience (specifically experience with C/C++). For good measure, we also asked if the subject had consumed caffeine the hours prior to the experiment.

            After these questions we put the devices on and ensure we get good signal by inspecting it in real time with the viewer provided by muse-lsl. The viewer itself does simple bandpass filtering between 3--40Hz, and the signal quality is indicated by the standard deviation of the filtered signal.

        \subsubsection{Devices}

            We experimented with several devices but eventually settled on the Muse S. The motivation for choosing the Muse S was mainly due to comfort and ease of use. The other devices considered included the OpenBCI Cyton (with Ultracortex headset), and the Neurosity Crown.\footnote{Earlier in the work, before we received the Crown, we were also generously gifted a Neurosity Notion DK1 to get a head start.}

            The Muse S is a 4-channel EEG headband with electrodes at TP9, AF7, AF8, and TP10, with the reference electrode at Fpz~\cite{krigolson_choosing_2017}.\footnote{According to the 10--20 system.}

            %\begin{minipage}

            %\begin{widepage}
                \begin{table}[h]
                \centering
                \begin{tabular}{llccc}
                    \toprule
                    Manufacturer
                    & Device
                    & Channels
                    & Sampling rate
                    & Comfort
                    \\
                    \midrule
                    InteraXon
                    & Muse S
                    & 4
                    & 250Hz
                    & High \\
                 OpenBCI
                    & Cyton (with Ultracortex)
                    & 8
                    & 125--250Hz
                    & Low \\
                 % generously gifted by Neurosity
                 %Neurosity
                 %   & Notion DK1
                 %   & 8
                 %   & 250Hz
                 %   & Medium \\
                  % preordered, arrives in late spring
                  Neurosity
                    & Crown
                    & 8
                    & 250Hz
                    & Medium \\
                    \bottomrule
                \end{tabular}
                \caption{Devices used}\label{table:devices}
            \end{table}
            %\end{widepage}

            %\begin{center}
                \begin{figure}[H]
                \centering
                %\begin{widepage}
                \begin{tabular}{c}
                    \includegraphics[width=80mm]{img/Muse-S.jpg}
                    \\
                    (a) Muse S
                    \\[6pt]
                    \includegraphics[width=80mm]{img/openbci-cyton.jpg}
                    \\
                    (b) OpenBCI Cyton with Ultracortex
                    \\[6pt]
                    \includegraphics[trim=0 100 0 0,clip,width=100mm]{img/crown-1.png}
                    \\
                    (c) Neurosity Crown
                    \\[6pt]
                \end{tabular}
                \caption{Photos of devices used}
                %\end{widepage}
            \end{figure}
            %\end{center}

            %\end{minipage}

    \subsection{Collection of device activity data}

        All device activity is collected using the automated time tracker ActivityWatch~\cite{bjareholt_activitywatch_2020-1}.

        ActivityWatch collects data through modules called watchers which report to the ActivityWatch server. It comes with two watchers by default:

        \begin{itemize}
            \item aw-watcher-window, tracks the active window and its title
            \item aw-watcher-afk, tracks if the user is active or not by observing input device activity
        \end{itemize}

        We've also built a custom watcher, aw-watcher-input, to track metrics of mouse and keyboard activity. It tracks by listening to mouse and keyboard events and records the distance\footnote{in pixels} the mouse moves and number of clicks (but not which key was clicked). Every second this is bundled into an event, the values are reset, and then it continues with the next event. It was inspired by similar functionality in Andrej Karpathy's ulogme~\cite{karpathy_ulogme_2016}.

        A limitation that we have to consider is that the window watcher uses a polling method to track the active window, with a default poll time of 1 second. This means that we can't rely on the timestamps to mark the exact time the window became active/inactive.

        The data from ActivityWatch is processed and categorized such that the resulting data has the 3 columns \mintinline{python}{start, end, category}. The category is determined by a regular expression that matches on window titles and URLs, such as \mintinline{python}{github.com}.

\section{Analysis}

    For classification and analysis, we used common open source Python libraries for data analysis, like numpy~\cite{harris2020array}, pandas~\cite{reback2020pandas}, and scikit-learn~\cite{scikit-learn}. In addition, we used less common libraries tailored specifically for working with EEG data, such as MNE~\cite{noauthor_mne-python_2020}, pyriemann~\cite{alexandre_barachant_2020_3715511}, and YASA~\cite{vallat_yasa_2020}.

    \subsection{Labelling}
        For the uncontrolled condition, we split the EEG data into epochs using the categories assigned by our ActivityWatch script.

        For the controlled experiment, we split the EEG data into epochs using the trial markers, resulting in one epoch per stimuli.

    \subsection{Data transformation}

        In order to train on the variable-length epochs, we need to split each epoch into a fixed-duration window, which can then we use to train and classify our model.

        Dimensions of each epoch matrix: \[ (n_{samples}, n_{channels}) \]

        Where $n_{samples}$ is the total number of samples for the epoch (variable-length), and $n_{channels}$ is 4 for the Muse S.

        Since the matrix has variable dimensions for each epoch, we split it into $\sim$5s windows, which at the 256Hz sampling frequency of the Muse gives us 1280 samples per window.

        Dimensions of the window matrix: \[ (n_{windows}, n_{channels}, 1280) \]

        We experimented with different windowing methods to potentially augment the data...  \todo[inline]{...and? Should a sliding window approach be used to improve data augmentation?}

    \subsection{Data cleaning}

        % TODO: Should this say 'reject windows' instead?
        We reject samples that either:

        \begin{enumerate}
            \item Don't have an assigned class
            \item Have a bad signal quality (as indicated by a high signal variance)
            \item Are too short (due to missing samples)
        \end{enumerate}

        \todo[inline]{List how many epochs are rejected by each cleaning step}

    \subsection{Feature engineering}

        One approach to classifying EEG data is to perform feature extraction/engineering. Common features used for EEG data include bandpower ratios, as well as covariance matrixes using the Riemannian metric.

        To evaluate most common machine learning classifiers, we need to

        \subsubsection{Bandpower}

            \todo[inline]{Refer/move to theory section instead?}

            Bandpower features are simple and commonly used in EEG research for many tasks, including the paper by Fucci et al we seek to improve upon~\cite{fucci_replication_2019}. As a reference, we implemented classifiers which solely used bandpower features as input, to gain information of how much any improvement from classifier performance is likely due to better EEG equipment versus how much is due to from improved analysis methods.

            To compute this feature, we utilized the bandpower function provided by YASA~\cite{vallat_yasa_2020}. The implementation estimates the power spectral density using Welch's method for each channel, and bins them by their associated frequency band.

            To further enrich our feature vector, we can use ratios between two frequency bands.

        \subsubsection{Riemannian geometry}

            \todo[inline]{Refer/move to theory section instead?}

            The \improvement{according to whom?}{state of the art in many EEG classification tasks} involves the use of Riemannian geometry. For this, we used the open source pyriemann library by Alexandre Barachant\footnote{First author of the original paper to apply Riemannian geometry to EEG~\cite{barachant_classification_2013}}.

    \subsection{Neural Networks}

        One of the classifiers we want to train is a neural network. We use braindecode~\cite{schirrmeister_deep_2017}\cite{noauthor_braindecode_2021}, a neural network toolbox for EEG data that uses PyTorch and integrates it with scikit-learn through skorch.

        The networks provided by braindecode are convolutional\ldots

    \subsection{Cross Validation}

        We use LORO (``Leave-One-Run-Out'') cross-validation, a variation of LOGO (``Leave-One-Group-Out''), in order to ensure the samples used in validation are using subjects or tasks that are unseen in training.

        We attempt both out-of-subject validation and out-of-task validation in order to estimate the ability of the classifiers to generalize across subjects and tasks.

    \subsection{Single subject}

        % TODO: what experiments?
        % TODO: what devices?
        % FIXME: is this out of scope?
        We experimented with single-subject analysis to validate different devices and tasks.
