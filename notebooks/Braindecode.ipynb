{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Braindecode\n",
    "\n",
    "Attempting to classify data using (convolutional) neural nets to compare performance.\n",
    "\n",
    "# TODO: Refactor data loading in Main.ipynb and call from here to get epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./Main.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use braindecode we need to transform our data to the braindecode format\n",
    "\n",
    "from braindecode.datasets import create_from_X_y\n",
    "\n",
    "# This wants X to be in the shape (x_trials, n_channels, n_samples)\n",
    "Xb, yb, subjb, imgb, sessb, tsb = zip(*epochs)\n",
    "\n",
    "Xb = [x.to_numpy().T for x in Xb]\n",
    "print(len(Xb), Xb[0].shape)\n",
    "\n",
    "yb = np.array([0 if yy == 'code' else 1 for yy in y])\n",
    "print(yb.shape)\n",
    "\n",
    "windows_dataset = create_from_X_y(\n",
    "    Xb, yb, drop_last_window=True, sfreq=sfreq, ch_names=list(eeg.columns),\n",
    "    window_stride_samples=512,\n",
    "    window_size_samples=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_dataset.description['group'] = subjb\n",
    "windows_dataset.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homegrown LORO\n",
    "splitted = windows_dataset.split('group')\n",
    "\n",
    "# Subject to use for validation\n",
    "subj_val = 5\n",
    "\n",
    "train_sets = [v for k, v in splitted.items() if k != str(subj_val)]\n",
    "\n",
    "train_set = train_sets[0]\n",
    "for ts in train_sets[1:]:\n",
    "    train_set += ts\n",
    "    \n",
    "valid_set = splitted[str(subj_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_set[0])\n",
    "print(train_set[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet, Deep4Net\n",
    "\n",
    "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "if cuda:\n",
    "    print(\"CUDA available!\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "# Set random seed to be able to reproduce results\n",
    "seed = 20200220\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "# Extract number of chans and time steps from dataset\n",
    "n_classes = len(set(y))\n",
    "n_chans = train_set[0][0].shape[0]\n",
    "input_window_samples = train_set[0][0].shape[1]\n",
    "\n",
    "print(f\"classes:   {n_classes}\")\n",
    "print(f\"channels:  {n_chans}\")\n",
    "print(f\"samples per window:  {input_window_samples}\")\n",
    "\n",
    "models = [\n",
    "    (\n",
    "        ShallowFBCSPNet(\n",
    "            n_chans,\n",
    "            n_classes,\n",
    "            input_window_samples=input_window_samples,\n",
    "            final_conv_length='auto',\n",
    "        ), \n",
    "        {\"lr\": 0.0625 * 0.01, \"weight_decay\": 0}\n",
    "    ),\n",
    "    (\n",
    "        Deep4Net(\n",
    "            n_chans, \n",
    "            n_classes, \n",
    "            input_window_samples=input_window_samples,\n",
    "            final_conv_length='auto'\n",
    "        ), \n",
    "        {\"lr\": 1 * 0.01, \"weight_decay\": 0.5 * 0.001}\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "\n",
    "from braindecode import EEGClassifier\n",
    "\n",
    "batch_size = 64\n",
    "n_epochs = 10\n",
    "\n",
    "nn_clfs = []\n",
    "for model, params in models:\n",
    "    clf = EEGClassifier(\n",
    "        model,\n",
    "        criterion=torch.nn.NLLLoss,\n",
    "        optimizer=torch.optim.AdamW,\n",
    "        train_split=predefined_split(valid_set),  # using valid_set for validation\n",
    "        optimizer__lr=params[\"lr\"],\n",
    "        optimizer__weight_decay=params[\"weight_decay\"],\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[\n",
    "            \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "        ],\n",
    "        device='cuda' if cuda else 'cpu',\n",
    "    )\n",
    "    nn_clfs.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training for a specified number of epochs. `y` is None as it is already supplied in the dataset.\n",
    "for clf in nn_clfs:\n",
    "    logger.info(f\"==== Training {clf.module.__class__.__name__} ====\")\n",
    "    \n",
    "    # Send model to GPU\n",
    "    if cuda:\n",
    "        clf.module.cuda()\n",
    "        \n",
    "    # FIXME: Remove try/except when error is resolved\n",
    "    try:\n",
    "        clf.fit(train_set, y=None, epochs=n_epochs)\n",
    "    except Exception as e:\n",
    "        logger.exception(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erb-thesis",
   "language": "python",
   "name": "erb-thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
