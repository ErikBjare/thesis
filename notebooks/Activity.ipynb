{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity classification\n",
    "\n",
    "Classification of device activities (tracked with ActivityWatch) from EEG data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import logging\n",
    "from typing import Dict\n",
    "from collections import defaultdict\n",
    "from datetime import date\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import eegclassify\n",
    "from eegclassify import main, load, clean, features, preprocess, plot, transform\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set this to True to run on testing data\n",
    "simulate_test = False\n",
    "if simulate_test:\n",
    "    import os\n",
    "    os.environ['PYTEST_CURRENT_TEST'] = \"true\"\n",
    "    \n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams[\"font.family\"] = \"serif\"  # since we're including the figures in serif-typed tex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "document.title='erb-thesis/Activity - Jupyter'  // Set the document title to be able to track time spent working on the notebook with ActivityWatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and save into special variable that won't be overwritten (since loading takes a while)\n",
    "df_loaded = load.load_labeled_eeg2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split data into sessions to perform out-of-session cross-validation\n",
    "\n",
    "df_loaded.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "\n",
    "df = df_loaded\n",
    "df = preprocess.split_rows(df, min_duration=5)\n",
    "#df = clean.clean(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This says nothing about the actual number of samples, only the number of events\n",
    "plot.classdistribution(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_seconds_per_day_and_class(df) -> Dict[date, Dict[str, float]]:\n",
    "    all_dates = {d.date() for d in df['start']}\n",
    "    d: Dict[date, Dict[str, float]] = defaultdict(lambda: defaultdict(int))\n",
    "    for date in all_dates:\n",
    "        for idx, entry in df.iterrows():\n",
    "            if date == entry['start'].date():\n",
    "                d[date][entry['class']] += len(entry['raw_data']) / 256\n",
    "    return d\n",
    "\n",
    "seconds_per_day_and_class = df_to_seconds_per_day_and_class(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{date: sum(seconds_per_day_and_class[date].values()) for date in seconds_per_day_and_class.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.DataFrame(seconds_per_day_and_class).T\n",
    "combined_df = combined_df[(combined_df.T.sum() > 100 * 5)]    # at least 100x 5s windows for each date\n",
    "combined_df = combined_df.T[(combined_df.sum() > 100 * 5)].T  # at least 100x 5s windows for each class\n",
    "combined_df = combined_df.sort_index(axis=0).sort_index(axis=1)\n",
    "combined_df = combined_df.filter(['Editing->Code', 'Editing->Prose', 'Twitter', 'YouTube'])\n",
    "combined_df = combined_df.rename({'Editing->Code': 'Programming', 'Editing->Prose': 'Writing'}, axis=1)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(combined_df[::-1]/60).plot.barh()\n",
    "#plt.label(\"Date\")\n",
    "plt.xlabel(\"Minutes of data\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.sum().plot.bar(rot=0, stacked=True)\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Seconds of data\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we do PCA on the signal?\n",
    "\n",
    "logging.getLogger('eegclassify.transform').setLevel(logging.ERROR)\n",
    "X, y = transform.signal_ndarray(df)\n",
    "print(X.shape)\n",
    "#plot.pca(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = []\n",
    "\n",
    "# all classes with decent count\n",
    "all_dfs += [clean._remove_rare(df, \"class\", threshold_count=50)]\n",
    "\n",
    "# Code vs Prose\n",
    "all_dfs += [clean._select_classes(df, \"class\", [\"Editing->Code\", \"Editing->Prose\"])]\n",
    "\n",
    "# Code vs Twitter\n",
    "all_dfs += [clean._select_classes(df, \"class\", [\"Editing->Code\", \"Twitter\"])]\n",
    "\n",
    "# Code vs YouTube\n",
    "all_dfs += [clean._select_classes(df, \"class\", [\"Editing->Code\", \"YouTube\"])]\n",
    "\n",
    "# Prose vs Twitter\n",
    "all_dfs += [clean._select_classes(df, \"class\", [\"Editing->Prose\", \"Twitter\"])]\n",
    "\n",
    "# Prose vs YouTube (roughly same class size)\n",
    "all_dfs += [clean._select_classes(df, \"class\", [\"Editing->Prose\", \"YouTube\"])]\n",
    "\n",
    "# Twitter vs YouTube\n",
    "all_dfs += [clean._select_classes(df, \"class\", [\"Twitter\", \"YouTube\"])]\n",
    "\n",
    "# GitHub PR vs issue\n",
    "#all_dfs += [clean._select_classes(df, \"class\", [\"GitHub->Issues\", \"GitHub->Pull request\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "from collections import Counter\n",
    "import importlib\n",
    "importlib.reload(eegclassify.main)\n",
    "importlib.reload(eegclassify.transform)\n",
    "\n",
    "for df_train in all_dfs:\n",
    "    print(Counter(df_train['class']))\n",
    "    print(f\"Hours of data: {round(len(df_train['class']) * 5 / 60 / 60, 2)}\")\n",
    "    try:\n",
    "        main._train_raw(df_train, shuffle=True)\n",
    "    except Exception as e:\n",
    "        # TODO: Fix testing data such that it doesn't err\n",
    "        print(\"Error while training\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_train in all_dfs:\n",
    "    print(len(df_train))\n",
    "    try:\n",
    "        main._train_features(df_train)\n",
    "    except Exception as e:\n",
    "        # TODO: Fix testing data such that it doesn't err\n",
    "        logger.exception(\"Error while training\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erb-thesis",
   "language": "python",
   "name": "erb-thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
