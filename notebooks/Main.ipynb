{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main analysis\n",
    "\n",
    "The primary analysis for the thesis, where we train a classifier for the code vs prose task.\n",
    "\n",
    "Other notebooks that are available:\n",
    "\n",
    " - Signal - for signal filtering and quality checking\n",
    " - Activities (TODO) - for classification of device activities (currently the content of this notebook, but it is to be moved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from eegclassify import main, load, clean, features, preprocess\n",
    "\n",
    "# Set this to True to run on testing data\n",
    "simulate_test = False\n",
    "if simulate_test:\n",
    "    import os\n",
    "    os.environ['PYTEST_CURRENT_TEST'] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "document.title='erb-thesis/Main - Jupyter'  // Set the document title to be able to track time spent working on the notebook with ActivityWatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and save into special variable that won't be overwritten (since loading takes a while)\n",
    "df_loaded = load.load_labeled_eeg2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into sessions (by date) for LORO CV\n",
    "\n",
    "df_loaded.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "\n",
    "df = df_loaded\n",
    "df = preprocess.split_rows(df, min_duration=5)\n",
    "#df = clean.clean(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, y = main.df_to_vectors(df)\n",
    "#main.pca(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = _remove_rare(df, \"class\", threshold_count=50)\n",
    "df = clean._select_classes(\n",
    "    df,\n",
    "    \"class\",\n",
    "    [\"Editing->Code\", \"Editing->Prose\"] #, \"GitHub->Issues\", \"GitHub->Pull request\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "try:\n",
    "    main._train_raw(df)\n",
    "except Exception as e:\n",
    "    # TODO: Fix testing data such that it doesn't err\n",
    "    print(\"Error while training\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    main._train_features(df)\n",
    "except Exception as e:\n",
    "    # TODO: Fix testing data such that it doesn't err\n",
    "    print(\"Error while training\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erb-thesis",
   "language": "python",
   "name": "erb-thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
