{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main analysis\n",
    "\n",
    "The primary analysis for the thesis, where we train a classifier for the code vs prose task.\n",
    "\n",
    "---\n",
    "\n",
    "### Table of Contents\n",
    "    \n",
    " - [Setup](#Setup)\n",
    "   - Imports\n",
    "   - Configuration\n",
    " - [Loading](#Loading)\n",
    "   - Loading EEG data\n",
    "   - Loading markers\n",
    " - [Preprocessing](#Preprocessing)\n",
    "   - Filter short trials\n",
    "   - Filter no answer trials\n",
    "   - Bandpass filtering\n",
    "   - Constructing epochs\n",
    "   - Epochs to windows\n",
    "   - Constructing our `X` and `y`\n",
    " - [Training](#Training)\n",
    "   - Learning curves\n",
    "      \n",
    "**NOTE:** This TOC is manually built and may not be up to date.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import re\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from typing import Dict\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from sklearn.base import clone\n",
    "\n",
    "from eegclassify import main, load, clean, features, preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "This cell contains all the configuration options available for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "use_bandpass_filter = True\n",
    "classify_breaks = False\n",
    "single_subject = None    # set to subject number, or False\n",
    "balance_dataset = True\n",
    "min_task_duration = 5\n",
    "standardize = False\n",
    "sliding_windows = True\n",
    "\n",
    "# Constants\n",
    "sfreq = 256  # sampling frequency of the Muse S\n",
    "\n",
    "# Color maps\n",
    "cmap = matplotlib.cm.get_cmap('RdYlGn')\n",
    "cmap_discrete = matplotlib.cm.get_cmap('Paired')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(format=\"%(levelname)s: %(msg)s\", level=logging.INFO, force=True)\n",
    "logger = logging.getLogger(__name__)\n",
    "mne.set_log_level('WARNING')\n",
    "\n",
    "# Set this to True to run on testing data\n",
    "simulate_test = False\n",
    "if simulate_test:\n",
    "    import os\n",
    "    os.environ['PYTEST_CURRENT_TEST'] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "document.title='erb-thesis/Main - Jupyter'  // Set the document title to be able to track time spent working on the notebook with ActivityWatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading EEG\n",
    "\n",
    "First we need to load the EEG data used during the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../data').resolve()\n",
    "    \n",
    "files = sorted([\n",
    "    *list((data_dir / \"tasks/visual-codeprose/subject0000/session000/\").glob(\"recording_*.csv\")),\n",
    "    *list((data_dir / \"tasks/visual-codeprose/subject0001/session000/\").glob(\"recording_*.csv\")),\n",
    "    *list((data_dir / \"tasks/visual-codeprose/subject0003/session000/\").glob(\"recording_*.csv\")),\n",
    "    *list((data_dir / \"tasks/visual-codeprose/subject0004/session000/\").glob(\"recording_*.csv\")),\n",
    "    *list((data_dir / \"tasks/visual-codeprose/subject0005/session000/\").glob(\"recording_*.csv\")),\n",
    "])\n",
    "pprint(files)\n",
    "\n",
    "eeg = load.load_eeg(files)\n",
    "eeg = eeg.set_index('timestamp').sort_index()\n",
    "print(eeg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at the loaded data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_eeg(X, offset, window, span=None):\n",
    "    plt.figure(figsize=(20, 3))\n",
    "    data = X[offset : offset + window, :]\n",
    "    plt.plot(data)\n",
    "    plt.xlim(0, window);\n",
    "    if span is None:\n",
    "        span = max(np.std(data, axis=1))\n",
    "    plt.ylim(-span, span);\n",
    "\n",
    "plot_eeg(eeg.to_numpy(), offset = 1000, window = 3 * sfreq)\n",
    "plot_eeg(eeg.to_numpy(), offset = 20000, window = 3 * sfreq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that some channels are bad some of the time, we will deal with that later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading markers\n",
    "\n",
    "Now we need to load the markers produced during each trial of the experiment, so we can annotate the EEG data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_files = [\n",
    "    data_dir / 'tasks/visual-codeprose/subject0000/session000/subject0_session0_behOutput_2021-04-02-14.28.30.csv',\n",
    "    data_dir / 'tasks/visual-codeprose/subject0001/session000/subject1_session0_behOutput_2021-03-26-14.31.14.csv',\n",
    "    data_dir / 'tasks/visual-codeprose/subject0003/session000/subject3_session0_behOutput_2021-05-28-19.21.35.csv',\n",
    "    data_dir / 'tasks/visual-codeprose/subject0004/session000/subject4_session0_behOutput_2021-05-28-19.54.14.csv',\n",
    "    data_dir / 'tasks/visual-codeprose/subject0005/session000/subject5_session0_behOutput_2021-05-28-20.36.34.csv',\n",
    "]\n",
    "\n",
    "def _build_breaks(df):\n",
    "    starts = df['t_answered'].iloc[:-1].shift()\n",
    "    starts_utc = df['t_answered_utc'].iloc[:-1].shift()\n",
    "    stops = df['t_presented'].iloc[1:]\n",
    "    stops_utc = df['t_presented_utc'].iloc[1:]\n",
    "    \n",
    "    breaks = pd.DataFrame({\n",
    "        \"t_presented\": starts, \n",
    "        \"t_answered\": stops, \n",
    "        \"t_presented_utc\": starts_utc, \n",
    "        \"t_answered_utc\": stops_utc, \n",
    "        \"type\": \"relax\", \n",
    "        \"duration\": stops - starts, \n",
    "        'subject': df['subject'],\n",
    "        'image_path': 'none',\n",
    "        'response': 'up',  # as placeholder\n",
    "    })\n",
    "    return breaks\n",
    "\n",
    "dfs = []\n",
    "for file in marker_files:\n",
    "    df = pd.read_csv(file, index_col=0)\n",
    "    df['duration'] = df['t_answered'] - df['t_presented']\n",
    "    match = re.search('subject(\\d+)', str(file))\n",
    "    assert match\n",
    "    df['subject'] = int(match.group(1))\n",
    "    \n",
    "    if classify_breaks:\n",
    "        breaks = _build_breaks(df)\n",
    "        df = df.append(breaks)\n",
    "    dfs.append(df)\n",
    "df_markers = pd.concat(dfs).sort_values(by=['subject', 't_presented'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at some of the marker rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_markers['img'] = df_markers['image_path'].apply((lambda c: c.split(\"/\")[-1]))\n",
    "df_markers.drop(columns=['image_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(set(df_markers['subject'])), figsize=(16, 4), sharey=True)\n",
    "for subject, ax in zip(set(df_markers['subject']), axs):\n",
    "    #plt.figure()\n",
    "    ax.set_title(f\"Subject {subject}\")\n",
    "    _df = df_markers[df_markers['subject'] == subject]\n",
    "    _df = _df[_df[\"response\"] != \"space\"]\n",
    "    _df['duration'].hist(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Now we need to preprocess the data a bit, gathering the EEG data for each trial in the experiment.\n",
    "\n",
    " - [ ] Better cleaning/rejection of bad epochs/windows/samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if single_subject is not None:\n",
    "    logger.info(f\"Selecting subject {single_subject}\")\n",
    "    n_prev = len(df_markers)\n",
    "    new_markers = df_markers[df_markers['subject'] == single_subject]\n",
    "    if not new_markers.empty:\n",
    "        df_markers = new_markers\n",
    "    print(f\"old size: {n_prev}, new size: {len(df_markers)}\")\n",
    "else:\n",
    "    logger.info(\"Using all subjects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter no answer trials\n",
    "\n",
    "We filter away rows where space was clicked (didn't answer/skipped/unsure?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_prev = len(df_markers)\n",
    "df_markers = df_markers[df_markers['response'].isin(['up', 'down'])]\n",
    "print(f\"Filtered away {n_prev - len(df_markers)} epochs due skipped by subject\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter short trials\n",
    "\n",
    "We filter away rows where the subject didn't spend at least `min_task_duration` seconds with the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_prev = len(df_markers)\n",
    "df_markers = df_markers[df_markers['duration'] > min_task_duration]\n",
    "print(f\"Filtered away {n_prev - len(df_markers)} epochs due to short duration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bandpass filtering\n",
    "\n",
    " - [x] FIXME: Why is the signal shifted after filtering? Should this be accounted for somehow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Should this maybe be done per epoch/window to avoid discontinuities? (although discontinuities should be rare...)\n",
    "\n",
    "# Bandpass-filter the signal\n",
    "plot_offset = 10000\n",
    "filter_shift = sfreq - 50\n",
    "\n",
    "if use_bandpass_filter:\n",
    "    logger.info(\"Bandpass-filtering the signal\")\n",
    "    plot_eeg(eeg.to_numpy(), plot_offset, 10 * sfreq)\n",
    "    \n",
    "    eeg_clean = clean.filter(eeg)\n",
    "    \n",
    "    for ch_idx, col in enumerate(eeg.columns):\n",
    "        eeg[col][:-filter_shift] = eeg_clean[filter_shift:, ch_idx]\n",
    "        \n",
    "    # plot the new result\n",
    "    plot_eeg(eeg.to_numpy(), plot_offset, 10 * sfreq)\n",
    "else:\n",
    "    logger.info(\"Skipping bandpass filtering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential moving standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: This should be done per epoch/window to avoid discontinuities\n",
    "# NOTE: This is needed for the neural nets to behave\n",
    "\n",
    "if standardize:\n",
    "    from braindecode.datautil import exponential_moving_standardize\n",
    "    output = exponential_moving_standardize(eeg.to_numpy().T)\n",
    "    \n",
    "    for ch_idx, col in enumerate(eeg.columns):\n",
    "        eeg[col] = output.T[:, ch_idx]\n",
    "else:\n",
    "    logger.info(\"Skipping exponential standardize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eeg(eeg.to_numpy(), 10000, 10 * sfreq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing epochs\n",
    "\n",
    "Now we match up the EEG data with the markers to create our epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = []\n",
    "\n",
    "skip_first_s = 1  # skip first 1 second\n",
    "skip_last_s = 1   # skip last 1 second\n",
    "\n",
    "for _, row in df_markers.iterrows():\n",
    "    start = datetime.fromtimestamp(row['t_presented_utc'], timezone.utc) + timedelta(seconds=skip_first_s)\n",
    "    stop = datetime.fromtimestamp(row['t_answered_utc'], timezone.utc) - timedelta(seconds=skip_last_s)\n",
    "    epoch = eeg.truncate(start, stop)\n",
    "    \n",
    "    # Check that sample count aligns with epoch duration\n",
    "    data_duration = row['duration'] - skip_first_s - skip_last_s\n",
    "    expected_samples = round(data_duration * sfreq)\n",
    "    actual_samples = len(epoch)\n",
    "    diff = expected_samples - actual_samples\n",
    "    if abs(diff) > 5:\n",
    "        logger.warning(f\"Expected {expected_samples} samples, found {actual_samples}\")\n",
    "        \n",
    "    epochs.append((epoch, row['type'], row['subject'], row['img'], start))\n",
    "print(f\"epochs: {len(epochs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([np.std(epoch) for epoch, *_ in epochs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epochs to windows\n",
    "\n",
    "Now we split up the epochs into windows of a fixed size.\n",
    "\n",
    " - [ ] TODO: Use a sliding window approach, similar to the one in braindecode (needs care with CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split epochs into windows\n",
    "WINDOW_SIZE = int(min_task_duration * sfreq)\n",
    "WINDOW_STEP = 256\n",
    "\n",
    "if sliding_windows:\n",
    "    print(\"Using sliding window to generate windows\")\n",
    "else:\n",
    "    print(\"Not using sliding window to generate windows\")\n",
    "    WINDOW_STEP = WINDOW_SIZE\n",
    "\n",
    "windows = []\n",
    "for epoch, type, subject, img, timestamp in epochs:\n",
    "    for i in range(0, len(epoch), WINDOW_STEP):\n",
    "        #print(i, i+WINDOW_SIZE)\n",
    "        window = epoch.iloc[i:i+WINDOW_SIZE]\n",
    "        if len(window) == WINDOW_SIZE:\n",
    "            windows.append((window, type, subject, img, timestamp))\n",
    "        else:\n",
    "            logger.debug(f'epoch too small ({len(window)}), skipping')    \n",
    "\n",
    "print(f\"windows: {len(windows)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter away windows with bad signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_bad_signal = True\n",
    "if filter_bad_signal:\n",
    "    for window, *_ in windows:\n",
    "        # print(np.std(window))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing our `X` and `y`\n",
    " \n",
    "Now to actually construct matrices that we can feed into the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, subjs, imgs, ts = zip(*windows)\n",
    "X = np.array([x.to_numpy().T for x in X])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look at the signal in a few of the windows to make sure it looks ok\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "axs = fig.subplots(4, 1, sharex=True, sharey=True)\n",
    "for i, ax in enumerate(axs):\n",
    "    plt.ylim(-40, 40)\n",
    "    plt.xlim(0, WINDOW_SIZE)\n",
    "    ax.plot(X[i, :, :].T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)\n",
    "print(y.shape)\n",
    "print(Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjs = np.array(subjs)\n",
    "imgs = np.array(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Counter(subjs))\n",
    "print(Counter(imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import shuffle\n",
    "\n",
    "if balance_dataset:\n",
    "    assert len(set(y)) == 2, 'only supports two classes'\n",
    "    \n",
    "    c_y: dict = Counter(y)\n",
    "    c_smallest, min_count = min(c_y.items(), key=lambda t: t[1])\n",
    "    print(f\"Smallest class: {c_smallest} with {min_count} samples\")\n",
    "    \n",
    "    large_class_samples = np.argwhere(y != c_smallest).flatten()\n",
    "    other_class_samples = np.argwhere(y == c_smallest).flatten()\n",
    "    \n",
    "    # Randomly undersample the largest class\n",
    "    shuffle(large_class_samples)\n",
    "    subsample = large_class_samples[:min_count]\n",
    "    idx = np.array(sorted(np.concatenate([subsample, other_class_samples])))\n",
    "    X, y, subjs, imgs = X[idx], y[idx], subjs[idx], imgs[idx]\n",
    "    print(f\"Total samples: {len(y)}\")\n",
    "    \n",
    "    # Doesn't work as fit_resample expects X to be a 2D matrix\n",
    "    #from imblearn.under_sampling import RandomUnderSampler\n",
    "    #rus = RandomUnderSampler(random_state=0)\n",
    "    #X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "    #print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_colors = {\"code\": \"r\", \"prose\": \"b\"}\n",
    "\n",
    "for i, (xx, yy, ss, im) in enumerate(zip(X, y, subjs, imgs)):\n",
    "    # Label\n",
    "    plt.barh(0, 1, left=i, color=cmap_discrete(1 if yy == 'code' else 0))\n",
    "    \n",
    "    # Subject\n",
    "    plt.barh(-1, 1, left=i, color=cmap_discrete(ss))\n",
    "    \n",
    "    # Stdev\n",
    "    thres = 10\n",
    "    bad = 30\n",
    "    quality = 1 - (np.clip(np.std(xx), thres, bad) - thres) / (bad - thres)\n",
    "    plt.barh(-2, 1, left=i, color=cmap(quality))\n",
    "    plt.barh(-3, 1, left=i, color='g' if  np.std(xx) < 20 else 'r')\n",
    "\n",
    "plt.title(\"Classification\")\n",
    "plt.yticks([0, -1, -2], [\"label\", \"subj\", \"std\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Here we train our model using pyRiemann.\n",
    "\n",
    " - [ ] Much of this code is from eegclassify/main.py, code should probably be reused better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we set up the different classifiers we want to train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import LeaveOneGroupOut, learning_curve\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "from pyriemann.estimation import Covariances, ERPCovariances, XdawnCovariances\n",
    "from pyriemann.spatialfilters import CSP\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "\n",
    "\n",
    "# Fixes non-convergence for binary classification\n",
    "dual = set(y) == 2\n",
    "\n",
    "clfs: Dict[str, Pipeline] = {\n",
    "    # These four are from https://neurotechx.github.io/eeg-notebooks/auto_examples/visual_ssvep/02r__ssvep_decoding.html\n",
    "    \"CSP + Cov + TS\": make_pipeline(\n",
    "        Covariances(),\n",
    "        CSP(4, log=False),\n",
    "        TangentSpace(),\n",
    "        LogisticRegression(dual=dual),\n",
    "    ),\n",
    "    \"Cov + TS\": make_pipeline(\n",
    "        Covariances(), TangentSpace(), LogisticRegression(dual=dual)\n",
    "    ),\n",
    "    \"Xdawn + TS\": make_pipeline(\n",
    "        XdawnCovariances(2),\n",
    "        TangentSpace(metric='riemann'),\n",
    "        LogisticRegression()\n",
    "    ),\n",
    "    # Performs meh\n",
    "    #\"CSP + RegLDA\": make_pipeline(\n",
    "    #    Covariances(), CSP(4), LDA(shrinkage=\"auto\", solver=\"eigen\")\n",
    "    #),\n",
    "    # Performs badly\n",
    "    # \"Cov + MDM\": make_pipeline(Covariances(), MDM()),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we train each classifier and plot their respective confusion matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from eegclassify.util import unison_shuffled_copies\n",
    "from eegclassify.main import _performance\n",
    "\n",
    "for name, clf in clfs.items():\n",
    "    logger.info(f\"===== Training with {name} =====\")\n",
    "    clf = clone(clf)\n",
    "\n",
    "    # Shuffled split\n",
    "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "        X, y, test_size=0.5, shuffle=False\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    logger.info(f\"Test score: {clf.score(X_test, y_test)}\")\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    perf = _performance(y_test, y_pred)\n",
    "    logger.info(perf)\n",
    "    \n",
    "    disp = plot_confusion_matrix(clf, X_test, y_test,\n",
    "                                 display_labels=['code', 'prose'],\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize='true')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, clf in clfs.items():\n",
    "    logger.info(f\"===== Training with {name} =====\")\n",
    "    clf = clone(clf)\n",
    "    \n",
    "    ret = sklearn.model_selection.cross_validate(clf, X, y, cv=5, n_jobs=-1, return_estimator=True)\n",
    "    logger.info(f\"CV score (shuffled):   {ret['test_score']}\")\n",
    "    \n",
    "    clf_trained = ret[\"estimator\"][0]\n",
    "    \n",
    "    plot_confusion_matrix(clf_trained, X, y,\n",
    "                          display_labels=['code', 'prose'],\n",
    "                          cmap=plt.cm.Blues,\n",
    "                          normalize='true')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LORO/LOGO split, where we leave out one subject for each fold\n",
    "logo = LeaveOneGroupOut()\n",
    "groups = subjs\n",
    "\n",
    "# LORO\n",
    "for name, clf in clfs.items():\n",
    "    clf = clone(clf)\n",
    "    logger.info(f\"===== Training with {name} =====\")\n",
    "    \n",
    "    res = sklearn.model_selection.cross_validate(clf, X, y, cv=logo, groups=groups, n_jobs=-1, return_estimator=True)\n",
    "    score = res[\"test_score\"]\n",
    "    logger.info(f\"CV score (LORO):   {np.mean(score) :.3f} (mean), {np.std(score) :.3f} (std)\")\n",
    "    logger.info(f\"                   {score}\")\n",
    "    \n",
    "    clf_trained = res[\"estimator\"][3]\n",
    "    \n",
    "    # FIXME: This shouldn't run on the entire sample\n",
    "    plot_confusion_matrix(clf_trained, X, y,\n",
    "                          display_labels=['code', 'prose'],\n",
    "                          cmap=plt.cm.Blues,\n",
    "                          normalize='true')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves\n",
    "\n",
    "Now to check the learning curves and see if the train and validation scores converge.\n",
    "\n",
    "**Note:** Performance is currently terrible as there isn't enough data for the model to learn to generalize across subjects (easily seen by changing to shuffled CV).\n",
    "\n",
    "A great example of how to plot learning curves is available here: https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eegclassify.util import powspace\n",
    "\n",
    "for name, clf in clfs.items():\n",
    "    logger.info(f\"===== Training with {name} =====\")\n",
    "    clf = clone(clf)\n",
    "    \n",
    "    # We create shuffled versions of the dataset to ensure that all stimuli of the same type aren't in sequence\n",
    "    # (as is the case for subject 1 which didn't have shuffled stimuli)\n",
    "    x_l, y_l, groups_l = unison_shuffled_copies(X, y, groups)\n",
    "    #x_l, y_l, groups_l = X, y, groups\n",
    "    \n",
    "    # We build a train_sizes to train across several sample sizes\n",
    "    groups_c: dict = Counter(groups_l)\n",
    "    largest_group, largest_group_count = max(groups_c.items(), key=lambda g: g[1])\n",
    "    largest_loro_train = len(y) - largest_group_count\n",
    "    smallest_train = 10\n",
    "    \n",
    "    train_sizes = np.floor(powspace(smallest_train, largest_loro_train, power=4, num=10)) / largest_loro_train\n",
    "    # print(train_sizes)\n",
    "    \n",
    "    # Compute the learning curve\n",
    "    train_sizes, train_scores, valid_scores = learning_curve(\n",
    "        clf, x_l, y_l, groups=groups_l, \n",
    "        train_sizes=train_sizes, \n",
    "        cv=logo, n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    m = np.mean(train_scores, axis=1)\n",
    "    std = np.std(train_scores, axis=1)\n",
    "    plt.plot(train_sizes, m, label=\"training score\", marker='.')\n",
    "    plt.fill_between(train_sizes, m-std, m+std, alpha=0.2)\n",
    "    \n",
    "    m = np.mean(valid_scores, axis=1)\n",
    "    std = np.std(valid_scores, axis=1)\n",
    "    plt.plot(train_sizes, m, label=\"validation score\", marker='.')\n",
    "    plt.fill_between(train_sizes, m-std, m+std, alpha=0.2)\n",
    "    \n",
    "    plt.axhline(0.5, color='grey', linestyle='--', linewidth=0.8)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlim(train_sizes[0], train_sizes[-1])\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a specific subject for validation\n",
    "subj_val = 1\n",
    "idx_train = np.argwhere(subjs != subj_val).flatten()\n",
    "idx_test = np.argwhere(subjs == subj_val).flatten()\n",
    "\n",
    "X_train, y_train = X[idx_train], y[idx_train]\n",
    "X_test, y_test = X[idx_test], y[idx_test]\n",
    "\n",
    "# Fit the first classifier on the training set\n",
    "clf = clone(list(clfs.values())[0])\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predicted = clf.predict(X)\n",
    "\n",
    "label_colors = {\"code\": \"r\", \"prose\": \"b\"}\n",
    "img_to_id = {img: idx for idx, img in enumerate(sorted(set(imgs)))}\n",
    "\n",
    "print(Counter(subjs))\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "for i, (xx, yy, pred, subj, img) in enumerate(zip(X, y, predicted, subjs, imgs)):\n",
    "    # Label\n",
    "    plt.barh(0, 1, left=i, color=label_colors[yy])\n",
    "    \n",
    "    # Predicted\n",
    "    plt.barh(-1, 1, left=i, color=label_colors[pred])\n",
    "    \n",
    "    # Correct?\n",
    "    plt.barh(-2, 1, left=i, color='g' if pred == yy else 'r')\n",
    "    \n",
    "    # Subject\n",
    "    plt.barh(-3, 1, left=i, color=cmap_discrete(subj))\n",
    "    \n",
    "    # Stim\n",
    "    plt.barh(-4, 1, left=i, color=cmap_discrete(img_to_id[img] % 10))\n",
    "    \n",
    "    # Testset member\n",
    "    plt.barh(-5, 1, left=i, color='g' if i in idx_test else 'w')\n",
    "    \n",
    "    # Stdev\n",
    "    thres = 10\n",
    "    bad = 30\n",
    "    quality = 1 - (np.clip(np.std(xx), thres, bad) - thres) / (bad - thres)\n",
    "    plt.barh(-6, 1, left=i, color=cmap(quality))\n",
    "    plt.barh(-7, 1, left=i, color='g' if  np.std(xx) < 20 else 'r')\n",
    "\n",
    "plt.title(\"Classification\")\n",
    "plt.yticks([0, -1, -2, -3, -4, -5, -6, -7], [\"label\", \"predicted\", \"correct\", \"subj\", \"img\", \"testset\", \"quality (stdev)\", \"quality (thres)\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Braindecode stuff\n",
    "\n",
    "Here we'll experiment with braindecode (convnets) to compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use braindecode we need to transform our data to the braindecode format\n",
    "\n",
    "from braindecode.datautil import create_from_X_y\n",
    "\n",
    "# This wants X to be in the shape (x_trials, n_channels, n_samples)\n",
    "Xb, yb, subjb, imgb, tsb = zip(*epochs)\n",
    "Xb = [x.to_numpy().T for x in Xb]\n",
    "print(len(Xb), Xb[0].shape)\n",
    "yb = np.array([0 if yy == 'code' else 1 for yy in y])\n",
    "print(yb.shape)\n",
    "windows_dataset = create_from_X_y(\n",
    "    Xb, yb, drop_last_window=False, sfreq=sfreq, ch_names=list(eeg.columns),\n",
    "    window_stride_samples=512,\n",
    "    window_size_samples=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_dataset.description['group'] = subjb\n",
    "windows_dataset.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homegrown LORO\n",
    "splitted = windows_dataset.split('group')\n",
    "\n",
    "# Subject to use for validation\n",
    "subj_val = 5\n",
    "\n",
    "train_sets = [v for k, v in splitted.items() if k != str(subj_val)]\n",
    "\n",
    "train_set = train_sets[0]\n",
    "for ts in train_sets[1:]:\n",
    "    train_set += ts\n",
    "    \n",
    "valid_set = splitted[str(subj_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models import ShallowFBCSPNet, Deep4Net\n",
    "\n",
    "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "if cuda:\n",
    "    print(\"CUDA available!\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "# Set random seed to be able to reproduce results\n",
    "seed = 20200220\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "# Extract number of chans and time steps from dataset\n",
    "n_classes = len(set(y))\n",
    "n_chans = train_set[0][0].shape[0]\n",
    "input_window_samples = train_set[0][0].shape[1]\n",
    "\n",
    "print(f\"classes:   {n_classes}\")\n",
    "print(f\"channels:  {n_chans}\")\n",
    "print(f\"samples per window:  {input_window_samples}\")\n",
    "\n",
    "models = [\n",
    "    (\n",
    "        ShallowFBCSPNet(\n",
    "            n_chans,\n",
    "            n_classes,\n",
    "            input_window_samples=input_window_samples,\n",
    "            final_conv_length='auto',\n",
    "        ), \n",
    "        {\"lr\": 0.0625 * 0.01, \"weight_decay\": 0}\n",
    "    ),\n",
    "    (\n",
    "        Deep4Net(\n",
    "            n_chans, \n",
    "            n_classes, \n",
    "            input_window_samples=input_window_samples,\n",
    "            final_conv_length='auto'\n",
    "        ), \n",
    "        {\"lr\": 1 * 0.01, \"weight_decay\": 0.5 * 0.001}\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_set[0])\n",
    "print(train_set[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "\n",
    "from braindecode import EEGClassifier\n",
    "\n",
    "batch_size = 64\n",
    "n_epochs = 10\n",
    "\n",
    "nn_clfs = []\n",
    "for model, params in models:\n",
    "    clf = EEGClassifier(\n",
    "        model,\n",
    "        criterion=torch.nn.NLLLoss,\n",
    "        optimizer=torch.optim.AdamW,\n",
    "        train_split=predefined_split(valid_set),  # using valid_set for validation\n",
    "        optimizer__lr=params[\"lr\"],\n",
    "        optimizer__weight_decay=params[\"weight_decay\"],\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[\n",
    "            \"accuracy\", (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "        ],\n",
    "        device='cuda' if cuda else 'cpu',\n",
    "    )\n",
    "    nn_clfs.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training for a specified number of epochs. `y` is None as it is already supplied in the dataset.\n",
    "for clf in nn_clfs:\n",
    "    logger.info(f\"==== Training {clf.module.__class__.__name__} ====\")\n",
    "    \n",
    "    # Send model to GPU\n",
    "    if cuda:\n",
    "        clf.module.cuda()\n",
    "        \n",
    "    # FIXME: Remove try/except when error is resolved\n",
    "    try:\n",
    "        clf.fit(train_set, y=None, epochs=n_epochs)\n",
    "    except Exception as e:\n",
    "        logger.exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erb-thesis",
   "language": "python",
   "name": "erb-thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
